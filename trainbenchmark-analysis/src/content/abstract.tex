\pagenumbering{roman}
\setcounter{page}{1}

\selectlanguage{magyar}
%\hungarianParagraph

\englishParagraph
%----------------------------------------------------------------------------
% Abstract in Hungarian
%----------------------------------------------------------------------------
\chapter*{Kivonat}\addcontentsline{toc}{chapter}{Kivonat}

A gráf alapú adatmodellező, illetve adatbázis-kezelő keretrendszerek esetén kulcsfontosságú a minél nagyobb teljesítmény, illetve rövidebb válaszidő biztosítása, különösen az olyan alkalmazási területeken, ahol egyszerre több, strukturálisan összetett lekérdezést kell újra és újra kiértékelni egy folyamatosan változó (gráf)adatstruktúra felett. A modern, relációs adatmodellt elvető NoSQL technológiák terjedésével egyre nagyobb figyelmet kap az ilyen rendszerek teljesítőképessége és skálázhatósága, így az utóbbi években több olyan benchmark is megjelent, melynek fő célja az ilyen rendszerek teljesítőképességének, különösen a lekérdezések skálázhatóságának szisztematikus kiértékelése. 

A legtöbb mérési keretrendszer számításba vesz bemenet és teljesítmény leíró metrikákat, mint például a gráf csomópontjainak száma vagy a lekérdezések válaszideje, ugyanakkor nagyon nehéz az eredmények összehasonlítása, mert a méréshez használt bemenetek (gráfok, lekérdezések komplexitása, illetve a gráfon a mérés során végrehajtott változtatások jellege, összességében a \emph{terhelési profil}) igen nagy méret- és tulajdonságbeli eltéréseket mutatnak - ezekről pedig megelőző kutatási eredmények kimutatták, hogy jelentős és változó mértékben befolyásolhatják az egyes eszközök viselkedését, teljesítménykarakterisztikáját.
% Azonban, ezen keretrendszerek nem veszik figyelembe a gráf belső hálózatán végbemenő változásokat, és kizárólag egy struktúrájú gráfra koncentrálnak. 

A jelen dolgozat elsődleges célja, hogy - korábbi kutatásokat \cite{metric_ase} folytatva - kidolgozzon egy olyan mérési módszertant és hozzá kapcsolódó keretrendszert, amelynek segítségével a gráf alapú adatbázis-kezelő rendszerek teljesítménybeli összehasonlítása szisztematikusan és reprodukálhatóan hajtható végre. Fő eredményként a teljesítménymérés céljára különböző gráf topológiákat javasolunk, amelyek jellemzésére gráfmetrikákat definiálunk. A metrikák segítségével jellemezhető az egyes mérések nehézsége, illetve bizonyos eszközök esetén kapcsolatot is találhatunk a gráfokat jellemző metrikák és a lekérdezések futásidői között. A módszertan és a keretrendszer képességeinek bemutatására a dolgozat bemutat egy komplex esettanulmányt, mely magába foglalja számos kísérlet automatizált elvégzését és magasszintű statisztikai analízis eszközökkel támogatott kiértékelését is.

%, így metrikáink később felhasználhatóak a gráflekérdezések optimalizálása - jelenleg még nagyon kiforratlan - területén. 



\vfill
\selectlanguage{english}
\englishParagraph


%----------------------------------------------------------------------------
% Abstract in English
%----------------------------------------------------------------------------
\chapter*{Abstract}\addcontentsline{toc}{chapter}{Abstract}

Achieving high query evaluation performance represents a major practical challenge in graph-based data management and database systems, especially in application domains where several, structurally complex queries need to be continuously evaluated against a steadily changing input graph. With the prevalence of modern NoSQL databases, the scalability of such systems is getting more and more attention. This resulted in the development of several graph-oriented database benchmarks over the past several years, with the main focus on the systematic assessment of query evaluation performance.

While most of such measurement frameworks take common input and performance metrics as the basis of comparison (e.g. graph node count, query evaluation response time), it remains very difficult to compare the relative difficulty of individual measurements to each other. This is because the characteristics of the input (graphs, queries and their complexity, and graph manipulation operations executed during the measurements, combined the \emph{workload profile}) varies greatly between individual measurement scenarios, and such factors have been shown by previous research results to have a significant and varied effect on tool performance characteristics.

As a continuation of previous research~\cite{metric_ase}, the primary goal of this report is to establish a measurement methodology with its associated set of frameworks and tools, which can help in the systematic and reproducible assessment of performance and scalability of graph-oriented database systems. As the main result, we propose to use a carefully designed corpus of input graphs adhering to various topologies characterized by metrics. These metrics are useful to compare the relative difficulty of measurement scenarios, and for some tools we can use them to establish links between metric values and query evaluation response time. In order to illustrate the capabilities of the methodology and the framework, the report includes a complex case study that incorporates the automatic execution of many experiments, as well as statistical result analysis supported by high level tools.

%Several state-of-the-art benchmark frameworks exist that assess the performance and correctness of query evaluations as they create real world-like workloads and define suites of systematic queries. However, these benchmark frameworks rely on only one particular type of network and they do not concentrate on a significant alteration of the underlying graph. Although most of them define metrics for characterizing the specific aspects of performance (response time, query evaluations per hour, etc.), most of them lack such comprehensive metrics for the queries and the graph.
%As a consequence, they cannot determine the correlations between workload and performance.

%Due to the absence of metrics, it is difficult to give a precise characterization of the complexity for various benchmarks. Hence, it is difficult %to compare the benchmarks and the published results to each other.

%In order to provide solid foundations to characterize the complexity of graph benchmarks, we elaborate a benchmark framework for graph-based database systems.

%We use various graph metrics to describe the structure of the graph %create regression models to determine the relationships quantitatively.
%and use a varied set of graph topologies for benchmarking. This will allow us to perform in-depth analysis on the relationships between the structure of the graph in the database and the performance of the query evaluations. These results can be used to obtain advanced heuristics for the optimization of graph query engines. While the optimization of relational databases has well-known techniques documented by a wide literature, the problem for graph query engines is yet be discussed thoroughly.




%The performance of query evaluations depends on the topology of the model, and the complexity of the particular query. Our primary goal is that --- %by defining model and query-related quantitative metrics ---  to find a considerable connection between metrics and the performance, and thus, be %able to predict the query evaluation time.

%Based on the metrics and their effect to the performance, we are able to make decisions in design to achieve on the optimal performance. %Furthermore, this knowledge can be utilized in the area of real-time query optimization engines as well.

%We investigate various NoSQL database systems via regression analysis in order to find different model-related metrics that are suited to %characterize their performance appropriately. Based on a real model, we generate graphs with various topologies and distributions to find metrics %from different aspects.

%Furthermore, we explore that whether an arbitrarily structured model's performance is predictable via our regression analysis, and also predict %which database system from our scope can be associated to the model in order to achieve an optimal performance.

%Finally, being motivated by the real-time optimization engines, we search answers whether by reducing the cost of metric calculations, an arbitrary %model's performance is still predictable.


\vfill
\dolgozatnyelve
\defaultParagraph

\newcounter{romanPage}
\setcounter{romanPage}{\value{page}}
\stepcounter{romanPage}