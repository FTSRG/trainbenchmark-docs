%----------------------------------------------------------------------------
\chapter{Introduction}\addcontentsline{toc}{chapter}{\bevezeto}
%----------------------------------------------------------------------------

\section{Context}
Queries are the foundation of data-intensive applications. Therefore, a high-performance query engine is an essential component for a wide range of software systems, including transactional databases, knowledge-based systems and software engineering tools. Traditionally, most of the data was stored in relational databases. However, during the last decade a new generation of databases emerged, utilizing non-relational models. These systems, collectively known as NoSQL databases, include semantic databases (triplestores) and graph databases. As graphs are well-suited to model domains with a rich inner structure---\eg social networks, public roads and library data---these databases are commonly used in both academic and industrial systems.

\section{Problem Statement}
While there are well-established and widely accepted benchmarks for relational databases~\cite{tpc}, these cannot be adapted to graph databases as they usually operate on fundamentally different workloads. Semantic databases have been widely studied, considering different aspects of performance, correctness and completeness~\cite{sp2bench, berlin, dbpedia}. In the model-driven engineering (MDE) community, tool contests presented transformation cases to assess the usability, conciseness and performance of model transformations~\cite{ttc2015, ttc2014, ttc2013, ttc2011, ttc2010}. The NoSQL community also proposed various benchmarks, published on both the web~\cite{rodriguez_benchmark,dex_benchmark} and in research papers~\cite{DBLP:journals/ase/DayarathnaS14,McColl:2014:PEO:2567634.2567638}.

While all these benchmarks can be used to compare the performance of query engines, deriving general conclusions from the results or comparing the findings between different benchmarks is difficult. The generalizability of benchmark results is mostly limited by the lack of relevant metrics that could be used to assess an engineering problem and predict which technology would be best suited. Existing metrics emphasize a single aspect of the problem (most typically the size of the graph), while internal metrics (\eg used for optimizing query evaluation engines) are either not documented well or not accessible in a reusable way.

\section{Contributions}
Our research aims to provide a framework for categorizing various benchmarks. In this report, we present a set of common metrics to characterize the complexity of the graph and the queries. We designed and implemented a benchmark for homogeneous graphs, featuring a set of queries and a highly configurable framework capable of generating graphs in different sizes and various topologies. We make use of statistical methods to determine the relationship between the metrics and the performance of the databases.

\section{Structure of the Report}

The structure of the report is as follows. \autoref{chapter:background} introduces the theoretical concepts, \autoref{chapter:related_work} discusses the design of the framework, and \autoref{chapter:design} presents the architecture and workflow of the benchmark. \autoref{chapter:contribution} shows the benchmark setup and analyzes the benchmark results. \autoref{chapter:evaluation} concludes the report and outlines directions for future work.

